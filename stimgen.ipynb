{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import moviepy.editor as e\n",
    "import numpy.random as npr\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from tqdm import trange,tqdm\n",
    "import gizeh\n",
    "import torch\n",
    "from random import choice\n",
    "from pytorch_pretrained_biggan import BigGAN, truncated_noise_sample\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageEnhance\n",
    "from PIL import ImageFilter\n",
    "from pytorch_style_gan import *\n",
    "import shutil\n",
    "import gc\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP =os.path.join(os.getcwd(),'temp')\n",
    "if not os.path.isdir(TEMP):\n",
    "    os.mkdir(TEMP)\n",
    "\n",
    "def random_one_hot(dim=1000,n=1):\n",
    "    m = np.eye(dim)[np.random.choice(dim, n)]\n",
    "    return torch.from_numpy(m).type('torch.FloatTensor').cuda()\n",
    "\n",
    "\n",
    "def tensor_to_images(obj):\n",
    "    try:\n",
    "        import PIL\n",
    "    except ImportError:\n",
    "        raise ImportError(\"install Pillow: pip install Pillow\")\n",
    "\n",
    "    if not isinstance(obj, np.ndarray):\n",
    "        obj = obj.detach().numpy()\n",
    "\n",
    "    obj = obj.transpose((0, 2, 3, 1))\n",
    "    obj = np.clip(((obj + 1) / 2.0) * 256, 0, 255)\n",
    "\n",
    "    img = []\n",
    "    for i, out in enumerate(obj):\n",
    "        out_array = np.asarray(np.uint8(out), dtype=np.uint8)\n",
    "        img.append(out_array)\n",
    "    return img\n",
    "\n",
    "class NPEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.int32):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NPEncoder, self).default(obj)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "g_all.eval()\n",
    "g_all.to(device)\n",
    "\n",
    "def kind_map(kind):\n",
    "    kinds = ['color','cursor','bg','sg','move','close']\n",
    "    z = np.zeros(len(kinds))\n",
    "    index = kinds.index(kind)\n",
    "    z[index]=1.\n",
    "    return z\n",
    "\n",
    "def annotate(kind=None, num_samples = None , data=None, c_speed = None, a_speed = None, truncation = None):\n",
    "    mat = np.empty((num_samples,784))\n",
    "    mat.fill(np.nan)\n",
    "    \n",
    "    # header (one hot vector for the kind of signal)\n",
    "    mat[:,0:6] = kind_map(kind)\n",
    "    \n",
    "    # speeds\n",
    "    if kind not in ['move', 'close'] :\n",
    "        mat[:,-2:] = [c_speed, a_speed]\n",
    "    if kind == 'cursor':\n",
    "        mat[:,6:13] = data\n",
    "    if kind == 'color':\n",
    "        mat[:,10:13] = data\n",
    "    if kind == 'sg':\n",
    "        mat[:,13:525] = data\n",
    "    if kind == 'bg':\n",
    "        mat[:,525:781] = data\n",
    "        mat[:,781] = truncation\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorScreen(data=None,dur=20,h=1024,w=1024,c_speed=1,fps=32, a_speed = np.nan, freeze_rate = 0.5):\n",
    "    if data is not None:\n",
    "        iM = 256*data[:,10:13]\n",
    "        mat = data\n",
    "        \n",
    "    else:\n",
    "        num_switches = int(dur*c_speed)+1\n",
    "        switch_samples = int(fps/c_speed)\n",
    "        num_samples = dur*fps\n",
    "\n",
    "        M = 255*npr.rand(num_switches,3) # main colors\n",
    "        M_freez_msk = npr.binomial(1, freeze_rate, (num_switches,3))        \n",
    "        for i in range(num_switches):\n",
    "            for j in range(3):\n",
    "                M[i,j] = (1-M_freez_msk[i,j])*M[i,j] + (M_freez_msk[i,j])*M[(i-1),j]\n",
    "\n",
    "\n",
    "        iM=np.empty((num_samples,3))\n",
    "        for i in range(num_switches-1):\n",
    "            iM[i*switch_samples:(i+1)*switch_samples] = np.linspace(M[i],M[i+1],switch_samples,endpoint=False)\n",
    "        mat = annotate(kind = 'color', num_samples = num_samples, data = iM/256., c_speed = c_speed, a_speed = np.nan)\n",
    "    imgs = [] # frames\n",
    "    for c in tqdm(iM):\n",
    "        img = np.empty((h, w, 3),dtype = np.uint8) # initialize the frame\n",
    "        img[:, :, 0:3] = c.astype(np.uint8)\n",
    "        imgs.append(img)\n",
    "    \n",
    "    clip = e.ImageSequenceClip(imgs,fps = fps)\n",
    "    fn = os.path.join(TEMP,time.strftime(\"%m-%d-%H-%M-%S\")+'.mp4')\n",
    "    clip.write_videofile(fn, fps = fps ,audio_codec='aac', logger = None)\n",
    "    cdur = clip.duration\n",
    "    del clip\n",
    "    gc.collect()\n",
    "    return fn,mat, cdur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorBoxScreen(data = None, dur=20,h=1024,a_speed=2,c_speed=1,fps=32,freeze_rate = 0.5):\n",
    "    if data is not None:\n",
    "        iM = data[:,6:13]\n",
    "        iM[:,0:4] = h * iM[:,0:4]\n",
    "        mat = data\n",
    "    \n",
    "    else:\n",
    "        num_switches_s = int(dur*a_speed)+1\n",
    "        num_switches_c = int(dur*c_speed)+1\n",
    "        switch_samples_s = int(fps/a_speed)\n",
    "        switch_samples_c = int(fps/c_speed)\n",
    "        num_samples = dur*fps\n",
    "\n",
    "        size = np.array([h,h])\n",
    "        Ss = npr.uniform([1,1],size/2,(num_switches_s,2)) #scales\n",
    "        Ps = npr.uniform(Ss,size-Ss,(num_switches_s,2)) #positions\n",
    "        C = npr.uniform(0,1,(num_switches_c,3)) #colors\n",
    "        G = np.concatenate([Ss,Ps],axis=1)\n",
    "        \n",
    "        G_freez_msk = npr.binomial(1, freeze_rate, (num_switches_s,4))        \n",
    "        for i in range(num_switches_s):\n",
    "            for j in range(4):\n",
    "                G[i,j] = (1-G_freez_msk[i,j])*G[i,j] + (G_freez_msk[i,j])*G[(i-1),j]\n",
    "                \n",
    "        C_freez_msk = npr.binomial(1, freeze_rate, (num_switches_c,3))\n",
    "        for i in range(num_switches_c):\n",
    "            for j in range(3):\n",
    "                C[i,j] = (1-C_freez_msk[i,j])*C[i,j] + (C_freez_msk[i,j])*C[(i-1),j]\n",
    "        \n",
    "        iG=np.empty((num_samples,4))\n",
    "        iC=np.empty((num_samples,3))\n",
    "        for i in range(num_switches_s-1):\n",
    "            iG[i*switch_samples_s:(i+1)*switch_samples_s] = np.linspace(G[i],G[i+1],switch_samples_s,endpoint=False)\n",
    "        for i in range(num_switches_c-1):\n",
    "            iC[i*switch_samples_c:(i+1)*switch_samples_c] = np.linspace(C[i],C[i+1],switch_samples_c,endpoint=False)\n",
    "        iM = np.concatenate([iG,iC],axis=1)\n",
    "        \n",
    "        data = iM.copy()\n",
    "        data[:,0:4] = data[:,0:4]/h\n",
    "        mat = annotate(kind='cursor', num_samples = num_samples, data = data, c_speed=c_speed, a_speed= a_speed)\n",
    "\n",
    "    imgs = [] # frames\n",
    "    n_blur=20\n",
    "    for m in tqdm(iM):\n",
    "        surface = gizeh.Surface(h,h) # width, height\n",
    "        s = m[0:2]\n",
    "        p = m[2:4]\n",
    "        c = m[4:]\n",
    "        for i in range(n_blur):\n",
    "            box = gizeh.rectangle(lx=s[0]+(n_blur-i),ly=s[1]+(n_blur-i), xy = p, fill=((i+1)/n_blur)*c)\n",
    "            box.draw(surface)\n",
    "        img = surface.get_npimage()\n",
    "        imgs.append(img)\n",
    "    clip = e.ImageSequenceClip(imgs,fps = fps)\n",
    "    fn = os.path.join(TEMP,time.strftime(\"%m-%d-%H-%M-%S\")+'.mp4')\n",
    "    clip.write_videofile(fn, fps = fps ,audio_codec='aac', logger = None)\n",
    "    cdur = clip.duration\n",
    "    del clip\n",
    "    gc.collect()\n",
    "    return fn,mat, cdur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceScreen(data = None, dur=30,h=1024,w=1024,c_speed=1,fps=32, a_speed=np.nan,freeze_rate = 0.5):\n",
    "    if data is not None:\n",
    "        iM = data[:,13:525]\n",
    "        mat = data\n",
    "    \n",
    "    else:    \n",
    "        num_switches = int(dur*c_speed)+1\n",
    "        switch_samples = int(fps/c_speed)\n",
    "        num_samples = dur*fps\n",
    "\n",
    "        M = npr.uniform(low=-3,high=3,size=(num_switches,512)) # main colors\n",
    "        M_freez_msk = npr.binomial(1, freeze_rate, (num_switches,512))        \n",
    "        for i in range(num_switches):\n",
    "            for j in range(512):\n",
    "                M[i,j] = (1-M_freez_msk[i,j])*M[i,j] + (M_freez_msk[i,j])*M[(i-1),j]\n",
    "\n",
    "        iM=np.empty((num_samples,512))\n",
    "        for i in range(num_switches-1):\n",
    "            iM[i*switch_samples:(i+1)*switch_samples] = np.linspace(M[i],M[i+1],switch_samples,endpoint=False)\n",
    "        mat = annotate(kind = 'sg', num_samples = num_samples, data = iM, c_speed=c_speed, a_speed=np.nan)    \n",
    "        \n",
    "    iMt = torch.from_numpy(iM)\n",
    "    iMt = iMt.to('cuda').float()\n",
    "    imgs = []\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0,len(iMt)):\n",
    "            imgs += tensor_to_images(g_all(iMt[i].unsqueeze(0)).cpu())\n",
    "    \n",
    "#     for c in iM:\n",
    "#         img = np.empty((h, w, 3)) # initialize the frame\n",
    "#         img[:, :, 0:3] = c\n",
    "#         imgs.append(img)\n",
    "    clip = e.ImageSequenceClip(imgs,fps = fps)\n",
    "    fn = os.path.join(TEMP,time.strftime(\"%m-%d-%H-%M-%S\")+'.mp4')\n",
    "    clip.write_videofile(fn, fps = fps ,audio_codec='aac', logger = None)\n",
    "    cdur = clip.duration\n",
    "    del clip\n",
    "    gc.collect()\n",
    "    return fn,mat, cdur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigGANScreen(data= None, dur=30, h=1024, w=1024, c_speed=1, a_speed=2, truncation=0.6, fps=32,freeze_rate = 0.5):\n",
    "    model = BigGAN.from_pretrained('biggan-deep-512',cache_dir='cache')\n",
    "    model.to('cuda')\n",
    "    \n",
    "    if data is not None:\n",
    "        condsnp = data[:,525:781]\n",
    "        truncation = data[0,781]\n",
    "        mat = data\n",
    "    else: \n",
    "        num_switches_y = int(dur*c_speed)+1\n",
    "        num_switches_z = int(dur*a_speed)+1\n",
    "        switch_samples_y = int(fps/c_speed)\n",
    "        switch_samples_z = int(fps/a_speed)\n",
    "        num_samples = dur*fps\n",
    "\n",
    "        Ys=np.empty((num_samples,128))\n",
    "        Zs=np.empty((num_samples,128))\n",
    "\n",
    "        y_oh = random_one_hot(dim=1000, n=num_switches_y)\n",
    "        y_freez_msk = npr.binomial(1, freeze_rate, (num_switches_y,1000))        \n",
    "        for i in range(1,num_switches_y):\n",
    "            for j in range(1000):\n",
    "                y_oh[i,j] = (1-y_freez_msk[i,j])*y_oh[i,j] + (y_freez_msk[i,j])*y_oh[(i-1),j]\n",
    "        y = np.array([model.embeddings(v).detach().cpu().numpy() for v in y_oh])\n",
    "        for i in range(num_switches_y-1):\n",
    "            Ys[i*switch_samples_y:(i+1)*switch_samples_y] = np.linspace(y[i],y[i+1],switch_samples_y,endpoint=False)\n",
    "            \n",
    "        z = truncated_noise_sample(truncation=truncation, batch_size=num_switches_z)\n",
    "        z_freez_msk = npr.binomial(1, freeze_rate, (num_switches_z,128))        \n",
    "        for i in range(1,num_switches_z):\n",
    "            for j in range(128):\n",
    "                z[i,j] = (1-z_freez_msk[i,j])*z[i,j] + (z_freez_msk[i,j])*z[(i-1),j]\n",
    "        for i in range(num_switches_z-1):\n",
    "            Zs[i*switch_samples_z:(i+1)*switch_samples_z] = np.linspace(z[i],z[i+1],switch_samples_z,endpoint=False)\n",
    "\n",
    "        condsnp = np.concatenate((Zs,Ys),axis = 1)\n",
    "        mat = annotate(kind='bg', num_samples= num_samples, data=condsnp, truncation=truncation, c_speed=c_speed, a_speed=a_speed)\n",
    "    \n",
    "    conds = torch.from_numpy(condsnp).type('torch.FloatTensor').cuda()\n",
    "    imgs = [] # frames\n",
    "    for i in trange(0,len(conds),3):\n",
    "        if i+3<len(conds):\n",
    "            tensors = model.generator(conds[i:i+3],truncation=truncation).detach().to('cpu').numpy()\n",
    "        else:\n",
    "            tensors = model.generator(conds[i:],truncation=truncation).detach().to('cpu').numpy()\n",
    "        imgs += [np.array(Image.fromarray(im).resize((h,w), resample=Image.BICUBIC)) for im in tensor_to_images(tensors)]\n",
    "    \n",
    "    clip = e.ImageSequenceClip(imgs,fps = fps)\n",
    "    fn = os.path.join(TEMP,time.strftime(\"%m-%d-%H-%M-%S\")+'.mp4')\n",
    "    clip.write_videofile(fn, fps = fps ,audio_codec='aac', logger = None)\n",
    "    cdur = clip.duration\n",
    "    del clip\n",
    "    gc.collect()\n",
    "    return fn,mat, cdur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeEyes():\n",
    "    num_samples = 32*10\n",
    "#     clip = e.VideoFileClip('close.mp4')\n",
    "    mat = annotate(kind = 'close', num_samples=num_samples)\n",
    "    return 'close.mp4', mat, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move():\n",
    "    num_samples = 32*15\n",
    "#    clip = e.VideoFileClip('move.mp4')\n",
    "    mat = annotate(kind = 'move', num_samples=num_samples)\n",
    "    return 'move.mp4', mat, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo(folder,total_dur=15,fps=32):\n",
    "    dur = 0\n",
    "    filled = 0\n",
    "    clips = []\n",
    "    mats = np.ndarray(dtype=np.float32, shape=(fps*(30+total_dur*60),784))\n",
    "\n",
    "    while dur<total_dur*60:\n",
    "        r = choice(range(20))\n",
    "        if r in range(2): # 10% close eyes\n",
    "            print('close ',dur/60)\n",
    "            clip,mat, cdur = closeEyes()\n",
    "        elif r in range(6) : # 20% move\n",
    "            print('move ',dur/60)\n",
    "            clip,mat, cdur = move()\n",
    "        elif r in range(8): # 10% color\n",
    "            print('color ',dur/60)\n",
    "            c_speed = choice([0.5,1,2])\n",
    "            clip,mat, cdur = colorScreen(c_speed=c_speed)\n",
    "        elif r in range(11): # 15% cursor\n",
    "            print('cursor ',dur/60)\n",
    "            c_speed = choice([0.5,1])\n",
    "            a_speed = choice([1,2,4])\n",
    "            clip,mat, cdur = colorBoxScreen(c_speed=c_speed, a_speed = a_speed)\n",
    "        elif r in range(15): # 20% sg\n",
    "            print('face ',dur/60)\n",
    "            c_speed = choice([0.2,0.5,1,2])\n",
    "            clip,mat, cdur = faceScreen(c_speed=c_speed)\n",
    "        else : # 25% bg\n",
    "            print('biggan ',dur/60)\n",
    "            c_speed = choice([0.2,0.5,1])\n",
    "            a_speed = choice([0.2,0.5,1,2])\n",
    "            clip,mat, cdur = bigGANScreen(c_speed=c_speed, a_speed = a_speed)\n",
    "        dur += cdur\n",
    "        clips.append(clip)\n",
    "        mats[filled:filled+len(mat),:] = mat\n",
    "        filled += len(mat)\n",
    "    print('reading the clips...')\n",
    "    clips = [e.VideoFileClip(c) for c in clips]\n",
    "    gc.collect()\n",
    "    clips = e.concatenate_videoclips(clips)\n",
    "    gc.collect()\n",
    "    mats = mats[:filled,:]\n",
    "    gc.collect()\n",
    "    timestr = time.strftime(\"%m-%d-%H-%M-%S\")\n",
    "    folder_path = os.path.join(folder,timestr)\n",
    "    os.mkdir(folder_path)\n",
    "    vid_fn = os.path.join(folder_path,'vid_'+timestr+'.mp4')\n",
    "    clips.write_videofile(vid_fn, fps = fps ,audio_codec='aac')\n",
    "    print('saving the log file ...')\n",
    "    log_fn = os.path.join(folder_path,'log_'+timestr)\n",
    "    np.save(log_fn,mats)\n",
    "    print('deleting temporary files ...')\n",
    "    del clips, mats\n",
    "    gc.collect()\n",
    "    for path in os.listdir(TEMP):\n",
    "        full_path = os.path.join(TEMP, path)\n",
    "        if os.path.isfile(full_path):\n",
    "            os.remove(full_path)\n",
    "    print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = 1\n",
    "duration = 5 # minutes\n",
    "\n",
    "exports =os.path.join(os.getcwd(),'exports')\n",
    "if not os.path.isdir(exports):\n",
    "    os.mkdir(exports) \n",
    "for _ in range(num_files):\n",
    "    combo(exports,total_dur=duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
